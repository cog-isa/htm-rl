# ====== Experiment config file =======
# By convention the filename should be prefixed with `expm_`
# The config has two semantic sections:
# 1. Declaration of all envs and agents to run
# 2. Declaration of the _current_ env-agent pair to run

# Both sections are optional and mutually exclusive - you either set multiple experiments
# or set just one. If the first section is set, then the second will be dynamically
# filled during the run for each pair.

# All additional flags related to the experiment config are placed here too.

# ====== Multiple experiments args ======

# Declares environments for the run. Options:
# 1. List of env config names w/o `env_` prefix. TODO: dict name: conf name
# 2. Dict of env <config name>: <config dict>
envs:
  - obs: obs

# Declares agents for the run. Format - same as `envs`.
agents:
  - rnd
  - ucb
  - svpn

# Declares a list of the environment seeds. See `X_seeds` for another way to declare.
env_seeds:
  - 711072
  - 482614
  - 743535

# Declares a list pf agent seeds. See `X_seeds` for another way to declare.
agent_seeds:
  - 42
  - 1337

# A variation of seed list declaration for environments/agents.
# This definition will be replaced by expanded generated list for resulting config.
X_seeds: !generate_seeds
  base: 8713
  n_seeds: 40

# ====== Single experiment args ======
n_episodes: 200

# wandb control options
wandb:
  enabled: false
  project:
  mode: dryrun
  silent: false

# Each experiment has one defined pair env-agent.
# It's required only if `Multiple experiments run args` section is absent.
# Otherwise, all possible env-agent seed-config pairs will be sequentially
# placed here, each - for a single run.
env_seed:
env:
agent_seed:
agent:


# ========= Environment config =========
# Sets all environment-related config variables.

# Config could be placed where env config dict is expected:
# 1. separate file prefixed with `env_`
# 2. in experiment config file in `envs`/`env`.

# Some first sections are the direct environment initialization args,
# the others declare variable number of optional modules. The order of modules
# declaration is important, e.g. food module makes use of areas/obstacles map
# to restrict the set of available cells.

# Declares the type of the environment. For now it isn't supported as we have
# only 1 env type. For the future use.
_type_: ...

shape_xy: [12, 12]

actions:
#  - stay
  - move right
  - move down
  - move left
  - move up

actions_cost:
  base_cost: -.0015
  weights:
    turn: 1.
    move: 1.

rendering:
  view_rectangle: [[-2, -2], [2, 2]]

areas:
  n_types: 4

obstacle:
  density: .25

food:
  n_items: 1
  reward: 1.

terminate:
  episode_max_steps: 350
  early_stop: true


# ========= Agent config =========
# Sets all agent-related config variables.

# Config could be placed where agent config dict is expected:
# 1. separate file prefixed with `agent_`
# 2. in experiment config file in `agents`/`agent`.

# Declares the type of an agent. The type is just a string that helps
# selecting an agent constructor.
_type_: svpn

.default_spatial_pooler_params: &default_spatial_pooler_params
  synapse_permanence_deltas: [ .1, .01 ]
  connected_permanence_threshold: .5
  min_activation_threshold: 1

state_sp:
  <<: *default_spatial_pooler_params
  output_dilation_ratio: 2.
  potential_synapses_ratio: .5
  sparsity: .015
  boost_strength: .2
  boost_sliding_window: 2000
  expected_normal_overlap_frequency: .001

action_encoder:
  bucket_size: 4

sa_sp:
  <<: *default_spatial_pooler_params
  output_dilation_ratio: 3.
  potential_synapses_ratio: .6
  sparsity: .015
  boost_strength: .2
  boost_sliding_window: 4000
  expected_normal_overlap_frequency: .001

sqvn:
  trace_decay: .75
  visit_decay: .994
  discount_factor: .96
  learning_rate: [.04, .995]
  ucb_exploration_factor: [.5, .994]
  td_error_decay: .0

dreamer:
  learning_rate: .5
  trace_decay: 0.

r_learning_rate: [.05, .995]
first_planning_episode: 0
last_planning_episode: 2000
prediction_depth: 10
n_prediction_rollouts: 2

tm:
  cells_per_column: 1
  initial_permanence: .5
  connected_permanence: .4
  activation_threshold: .9
  learning_threshold: .66
  max_new_synapse_count: 1.
  max_synapses_per_segment: 1.2
  predictedSegmentDecrement: .0001
  permanenceIncrement: .1
  permanenceDecrement: .03
  maxSegmentsPerCell: 4
