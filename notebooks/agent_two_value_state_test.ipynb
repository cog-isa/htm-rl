{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../htm_rl/htm_rl/')\n",
    "\n",
    "from agent.agent import Agent, AgentRunner\n",
    "from agent.memory import Memory, TemporalMemory\n",
    "from agent.planner import Planner\n",
    "from common.sa_sdr_encoder import SaSdrEncoder, format_sa_superposition\n",
    "from common.int_sdr_encoder import IntSdrEncoder, IntRangeEncoder\n",
    "from common.int_sdr_encoder import SequenceSdrEncoder\n",
    "from envs.gridworld_pomdp import GridWorld\n",
    "from common.base_sa import Sa\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Agent in gridworld environment with two-value state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_description = [[2,0,0],\n",
    "                     [1,1,0],\n",
    "                     [0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = GridWorld(world_description, (3, 3), agent_initial_position={'row': 2, 'column': 0},\n",
    "               observable_vars=['distance', 'surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.observable_state, gw.filtered_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_encoder = SequenceSdrEncoder('state',\n",
    "                                   encoders=[\n",
    "                                             IntSdrEncoder('distance',\n",
    "                                                                   gw.world_size[0] + 1,\n",
    "                                                                   5,\n",
    "                                                                   5),\n",
    "                                             IntSdrEncoder('surface', 3 + 1, 5, 5)\n",
    "                                            ],\n",
    "                                   size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder = IntSdrEncoder('action', gw.n_actions + 1,\n",
    "                              value_bits=5, activation_threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder = SaSdrEncoder(state_encoder, action_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder.total_bits, sa_encoder.value_bits, sa_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_state = (0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder = SaSdrEncoder(state_encoder, action_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder.total_bits, sa_encoder.value_bits, sa_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = sa_encoder.value_bits / sa_encoder.total_bits\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = dict(n_columns=sa_encoder.total_bits,\n",
    "                                cells_per_column=8,\n",
    "                                activation_threshold=sa_encoder.value_bits,\n",
    "                                learning_threshold=sa_encoder.value_bits,\n",
    "                                initial_permanence=0.6,\n",
    "                                connected_permanence=0.5,\n",
    "                                maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                                maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                                permanenceIncrement=0.1,\n",
    "                                permanenceDecrement=0.05,\n",
    "                                predictedSegmentDecrement=0.01)\n",
    "tm = TemporalMemory(**pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(tm, sa_encoder, sa_encoder.format, format_sa_superposition, start_indicator=Sa((3, 3), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = Planner(memory, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(memory, planner, gw.n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = AgentRunner(agent, gw, 100, max_steps, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.agent.planner.inter_episode_goal_memory._set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.agent.set_planning_horizon(10)\n",
    "run.max_steps = max_steps\n",
    "run.verbosity = 1\n",
    "run.pretrain = 0\n",
    "run.n_episodes = 10\n",
    "run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "steps = np.array(run.train_stats.steps[:])\n",
    "plt.plot(np.arange(steps.size), steps, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.mean(), steps.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#goal_state = (0, 2, -2, 1, 2)\n",
    "#run.agent.planner.add_goal(goal_state)\n",
    "run.agent.set_planning_horizon(10)\n",
    "run.max_steps = max_steps\n",
    "run.verbosity = 1\n",
    "run.pretrain = 0\n",
    "run.n_episodes = 1\n",
    "run.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
