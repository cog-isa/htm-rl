{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12).reshape((4, 3))\n",
    "x = np.array([6, 7, 8])\n",
    "(a == x).all(axis=1), np.argwhere((a == x).all(axis=1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_minigrid as mg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# fetch datasets from www.openML.org/ \n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from htm.bindings.algorithms import SpatialPooler, Classifier\n",
    "from htm.bindings.sdr import SDR, Metrics\n",
    "\n",
    "\n",
    "def load_ds(name, num_test, shape=None):\n",
    "    \"\"\" \n",
    "    fetch dataset from openML.org and split to train/test\n",
    "    @param name - ID on openML (eg. 'mnist_784')\n",
    "    @param num_test - num. samples to take as test\n",
    "    @param shape - new reshape of a single data point (ie data['data'][0]) as a list. Eg. [28,28] for MNIST\n",
    "    \"\"\"\n",
    "    data = fetch_openml(name, version=1)\n",
    "    sz=data['target'].shape[0]\n",
    "\n",
    "    X = data['data']\n",
    "    if shape is not None:\n",
    "        new_shape = shape.insert(0, sz)\n",
    "        X = np.reshape(X, shape)\n",
    "\n",
    "    y = data['target'].astype(np.int32)\n",
    "    # split to train/test data\n",
    "    train_labels = y[:sz-num_test]\n",
    "    train_images = X[:sz-num_test]\n",
    "    test_labels  = y[sz-num_test:]\n",
    "    test_images  = X[sz-num_test:]\n",
    "\n",
    "    return train_labels, train_images, test_labels, test_images\n",
    "\n",
    "def encode(data, out):\n",
    "    \"\"\"\n",
    "    encode the (image) data\n",
    "    @param data - raw data\n",
    "    @param out  - return SDR with encoded data\n",
    "    \"\"\"\n",
    "    out.dense = data >= np.mean(data) # convert greyscale image to binary B/W.\n",
    "    #TODO improve. have a look in htm.vision etc. For MNIST this is ok, for fashionMNIST in already loses too much information\n",
    "\n",
    "\n",
    "# These parameters can be improved using parameter optimization,\n",
    "# see py/htm/optimization/ae.py\n",
    "# For more explanation of relations between the parameters, see \n",
    "# src/examples/mnist/MNIST_CPP.cpp \n",
    "default_parameters = {\n",
    "    'potentialRadius': 7,\n",
    "    'boostStrength': 7.0,\n",
    "    'columnDimensions': (79, 79),\n",
    "    'dutyCyclePeriod': 1402,\n",
    "    'localAreaDensity': 0.1,\n",
    "    'minPctOverlapDutyCycle': 0.2,\n",
    "    'potentialPct': 0.1,\n",
    "    'stimulusThreshold': 6,\n",
    "    'synPermActiveInc': 0.14,\n",
    "    'synPermConnected': 0.5,\n",
    "    'synPermInactiveDec': 0.02\n",
    "}\n",
    "\n",
    "\n",
    "def main(parameters=default_parameters, argv=None, verbose=True):\n",
    "\n",
    "    # Load data.\n",
    "    train_labels, train_images, test_labels, test_images = load_ds('mnist_784', 10000, shape=[28,28]) # HTM: ~95.6%\n",
    "    #train_labels, train_images, test_labels, test_images = load_ds('Fashion-MNIST', 10000, shape=[28,28]) # HTM baseline: ~83%\n",
    "\n",
    "    training_data = list(zip(train_images, train_labels))\n",
    "    test_data     = list(zip(test_images, test_labels))\n",
    "    random.shuffle(training_data)\n",
    "\n",
    "    # Setup the AI.\n",
    "    enc = SDR(train_images[0].shape)\n",
    "    sp = SpatialPooler(\n",
    "        inputDimensions            = enc.dimensions,\n",
    "        columnDimensions           = parameters['columnDimensions'],\n",
    "        potentialRadius            = parameters['potentialRadius'],\n",
    "        potentialPct               = parameters['potentialPct'],\n",
    "        globalInhibition           = True,\n",
    "        localAreaDensity           = parameters['localAreaDensity'],\n",
    "        stimulusThreshold          = int(round(parameters['stimulusThreshold'])),\n",
    "        synPermInactiveDec         = parameters['synPermInactiveDec'],\n",
    "        synPermActiveInc           = parameters['synPermActiveInc'],\n",
    "        synPermConnected           = parameters['synPermConnected'],\n",
    "        minPctOverlapDutyCycle     = parameters['minPctOverlapDutyCycle'],\n",
    "        dutyCyclePeriod            = int(round(parameters['dutyCyclePeriod'])),\n",
    "        boostStrength              = parameters['boostStrength'],\n",
    "        seed                       = 0, # this is important, 0=\"random\" seed which changes on each invocation\n",
    "        spVerbosity                = 99,\n",
    "        wrapAround                 = False)\n",
    "    columns = SDR( sp.getColumnDimensions() )\n",
    "    columns_stats = Metrics( columns, 99999999 )\n",
    "    sdrc = Classifier()\n",
    "\n",
    "#     # Training Loop\n",
    "#     for i in range(len(train_images)):\n",
    "#         img, lbl = training_data[i]\n",
    "#         encode(img, enc)\n",
    "#         sp.compute( enc, True, columns )\n",
    "#         sdrc.learn( columns, lbl ) #TODO SDRClassifier could accept string as a label, currently must be int\n",
    "\n",
    "#     print(str(sp))\n",
    "#     print(str(columns_stats))\n",
    "\n",
    "#     # Testing Loop\n",
    "#     score = 0\n",
    "#     for img, lbl in test_data:\n",
    "#         encode(img, enc)\n",
    "#         sp.compute( enc, False, columns )\n",
    "#         if lbl == np.argmax( sdrc.infer( columns ) ):\n",
    "#             score += 1\n",
    "#     score = score / len(test_data)\n",
    "\n",
    "#     print('Score:', 100 * score, '%')\n",
    "#     return score\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_images, test_labels, test_images = load_ds('mnist_784', 10000, shape=[28,28]) # HTM: ~95.6%\n",
    "# train_labels, train_images, test_labels, test_images = load_ds('Fashion-MNIST', 10000, shape=[28,28]) # HTM baseline: ~83%\n",
    "\n",
    "training_data = list(zip(train_images, train_labels))\n",
    "test_data     = list(zip(test_images, test_labels))\n",
    "\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "train_images, train_labels = zip(*training_data)\n",
    "test_images, test_labels = zip(*test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def run_bare_classifier(parameters=default_parameters, argv=None, verbose=True):\n",
    "    training_data = list(zip(train_images, train_labels))\n",
    "    test_data     = list(zip(test_images, test_labels))\n",
    "    random.shuffle(training_data)\n",
    "\n",
    "    # Setup the AI.\n",
    "    enc = SDR(train_images[0].shape)\n",
    "    columns_stats = Metrics( enc, 99999999 )\n",
    "    sdrc = Classifier()\n",
    "\n",
    "    # Training Loop\n",
    "    for i in range(len(train_images)):\n",
    "        img, lbl = training_data[i]\n",
    "        encode(img, enc)\n",
    "        sdrc.learn( enc, lbl )\n",
    "\n",
    "    print(str(columns_stats))\n",
    "\n",
    "    # Testing Loop\n",
    "    score = 0\n",
    "    for img, lbl in test_data:\n",
    "        encode(img, enc)\n",
    "        if lbl == np.argmax( sdrc.infer( enc ) ):\n",
    "            score += 1\n",
    "    score = score / len(test_data)\n",
    "\n",
    "    print('Score:', 100 * score, '%')\n",
    "    return score\n",
    "\n",
    "run_bare_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def run_htm_sp(parameters=default_parameters, argv=None, verbose=True):\n",
    "    training_data = list(zip(train_images, train_labels))\n",
    "    test_data     = list(zip(test_images, test_labels))\n",
    "    random.shuffle(training_data)\n",
    "\n",
    "    # Setup the AI.\n",
    "    enc = SDR(train_images[0].shape)\n",
    "    sp = SpatialPooler(\n",
    "        inputDimensions            = enc.dimensions,\n",
    "        columnDimensions           = parameters['columnDimensions'],\n",
    "        potentialRadius            = parameters['potentialRadius'],\n",
    "        potentialPct               = parameters['potentialPct'],\n",
    "        globalInhibition           = True,\n",
    "        localAreaDensity           = parameters['localAreaDensity'],\n",
    "        stimulusThreshold          = int(round(parameters['stimulusThreshold'])),\n",
    "        synPermInactiveDec         = parameters['synPermInactiveDec'],\n",
    "        synPermActiveInc           = parameters['synPermActiveInc'],\n",
    "        synPermConnected           = parameters['synPermConnected'],\n",
    "        minPctOverlapDutyCycle     = parameters['minPctOverlapDutyCycle'],\n",
    "        dutyCyclePeriod            = int(round(parameters['dutyCyclePeriod'])),\n",
    "        boostStrength              = parameters['boostStrength'],\n",
    "        seed                       = 0, # this is important, 0=\"random\" seed which changes on each invocation\n",
    "        spVerbosity                = 99,\n",
    "        wrapAround                 = False)\n",
    "    columns = SDR( sp.getColumnDimensions() )\n",
    "    columns_stats = Metrics( columns, 99999999 )\n",
    "    sdrc = Classifier()\n",
    "\n",
    "    # Training Loop\n",
    "    for i in range(len(train_images)):\n",
    "        img, lbl = training_data[i]\n",
    "        encode(img, enc)\n",
    "        sp.compute( enc, True, columns )\n",
    "        sdrc.learn( columns, lbl )\n",
    "\n",
    "    print(str(sp))\n",
    "    print(str(columns_stats))\n",
    "\n",
    "    # Testing Loop\n",
    "    score = 0\n",
    "    for img, lbl in test_data:\n",
    "        encode(img, enc)\n",
    "        sp.compute( enc, False, columns )\n",
    "        if lbl == np.argmax( sdrc.infer( columns ) ):\n",
    "            score += 1\n",
    "    score = score / len(test_data)\n",
    "\n",
    "    print('Score:', 100 * score, '%')\n",
    "    return score\n",
    "\n",
    "run_htm_sp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def encode_to_csr(x, enc: SDR):    \n",
    "    encoded_images_flatten = []\n",
    "    indptr = [0]\n",
    "    for img in x_tr:\n",
    "        encode(img, enc)\n",
    "        encoded_images_flatten.extend(enc.sparse)\n",
    "        indptr.append(len(encoded_images_flatten))\n",
    "    \n",
    "    data = np.ones(len(encoded_images_flatten))\n",
    "    csr = csr_matrix((data, encoded_images_flatten, indptr))\n",
    "    return csr\n",
    "\n",
    "def run_bare_sklearn_classifier(x_tr,  y_tr, x_tst, y_tst, parameters=default_parameters):    \n",
    "    # Get training data\n",
    "    enc = SDR(train_images[0].shape)\n",
    "    csr = encode_to_csr(x_tr, enc)\n",
    "    \n",
    "    linreg = LogisticRegression(tol=.001, max_iter=100, multi_class='multinomial', penalty='l2', solver='lbfgs', n_jobs=3)\n",
    "    linreg.fit(csr, y_tr)\n",
    "    \n",
    "    csr = encode_to_csr(x_tst, enc)\n",
    "    score = linreg.predict(csr) == y_tr\n",
    "    score = score.mean()\n",
    "    print('Score:', 100 * score, '%')\n",
    "    return score\n",
    "\n",
    "n = 100000\n",
    "x_tr, y_tr = train_images[:n], train_labels[:n]\n",
    "x_tst, y_tst = test_images[:n], test_labels[:n]\n",
    "\n",
    "run_bare_sklearn_classifier(x_tr, y_tr, x_tst, y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def encode_to_csr_sp(x, enc: SDR, sp, columns):            \n",
    "    encoded_images_flatten = []\n",
    "    indptr = [0]\n",
    "    for img in x_tr:\n",
    "        encode(img, enc)\n",
    "        sp.compute( enc, False, columns )\n",
    "        encoded_images_flatten.extend(columns.sparse)\n",
    "        indptr.append(len(encoded_images_flatten))\n",
    "\n",
    "    \n",
    "    data = np.ones(len(encoded_images_flatten))\n",
    "    csr = csr_matrix((data, encoded_images_flatten, indptr))\n",
    "    return csr\n",
    "\n",
    "\n",
    "def run_htm_sp_sklearn(x_tr,  y_tr, x_tst, y_tst, parameters=default_parameters):\n",
    "    test_data     = list(zip(x_tst, y_tst))\n",
    "    \n",
    "    # Get training data\n",
    "    enc = SDR(train_images[0].shape)\n",
    "    sp = SpatialPooler(\n",
    "        inputDimensions            = enc.dimensions,\n",
    "        columnDimensions           = parameters['columnDimensions'],\n",
    "        potentialRadius            = parameters['potentialRadius'],\n",
    "        potentialPct               = parameters['potentialPct'],\n",
    "        globalInhibition           = True,\n",
    "        localAreaDensity           = parameters['localAreaDensity'],\n",
    "        stimulusThreshold          = int(round(parameters['stimulusThreshold'])),\n",
    "        synPermInactiveDec         = parameters['synPermInactiveDec'],\n",
    "        synPermActiveInc           = parameters['synPermActiveInc'],\n",
    "        synPermConnected           = parameters['synPermConnected'],\n",
    "        minPctOverlapDutyCycle     = parameters['minPctOverlapDutyCycle'],\n",
    "        dutyCyclePeriod            = int(round(parameters['dutyCyclePeriod'])),\n",
    "        boostStrength              = parameters['boostStrength'],\n",
    "        seed                       = 0, # this is important, 0=\"random\" seed which changes on each invocation\n",
    "        spVerbosity                = 0,\n",
    "        wrapAround                 = False)\n",
    "    columns = SDR( sp.getColumnDimensions() )\n",
    "\n",
    "    # train SP\n",
    "    for img in x_tr:\n",
    "        encode(img, enc)\n",
    "        sp.compute( enc, True, columns )\n",
    "    \n",
    "    # train linreg\n",
    "    csr = encode_to_csr_sp(x_tr, enc, sp, columns)\n",
    "    \n",
    "    linreg = LogisticRegression(tol=.001, max_iter=100, multi_class='multinomial', penalty='l2', solver='lbfgs', n_jobs=3)\n",
    "    linreg.fit(csr, y_tr)\n",
    "    \n",
    "    csr = encode_to_csr_sp(x_tst, enc, sp, columns)\n",
    "    score = linreg.predict(csr) == y_tr\n",
    "    score = score.mean()\n",
    "    print('Score:', 100 * score, '% for n =', len(x_tr))\n",
    "    return score\n",
    "\n",
    "n = 100000\n",
    "x_tr, y_tr = train_images[:n], train_labels[:n]\n",
    "x_tst, y_tst = test_images[:n], test_labels[:n]\n",
    "\n",
    "run_htm_sp_sklearn(x_tr, y_tr, x_tst, y_tst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
