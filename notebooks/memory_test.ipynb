{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../htm_rl/htm_rl/')\n",
    "\n",
    "from agent.agent import Agent, AgentRunner\n",
    "from agent.memory import Memory, TemporalMemory\n",
    "from agent.planner import Planner\n",
    "from common.sa_sdr_encoder import SaSdrEncoder, format_sa_superposition\n",
    "from common.base_sa import SaRelatedComposition, Sa, SaSuperposition\n",
    "from common.int_sdr_encoder import IntSdrEncoder, IntRangeEncoder\n",
    "from common.int_sdr_encoder import SequenceSdrEncoder\n",
    "from envs.gridworld_pomdp import GridWorld\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовый тест памяти с использованием новой кодироки состояний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_description = [[2,0,0],\n",
    "                     [1,1,0],\n",
    "                     [0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = GridWorld(world_description, (3, 3), agent_initial_position={'row': 2, 'column': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 12\n",
    "\n",
    "state_encoder = SequenceSdrEncoder('state',\n",
    "                                   encoders=[IntSdrEncoder('distance',\n",
    "                                                                   gw.world_size[0],\n",
    "                                                                   5,\n",
    "                                                                   4),\n",
    "                                             IntSdrEncoder('surface', 3, 5, 4),\n",
    "                                             IntRangeEncoder('row', (-(gw.world_size[0]-1),\n",
    "                                                                     gw.world_size[1]-1), 5, 4),\n",
    "                                             IntRangeEncoder('column', (-(gw.world_size[0]-1),\n",
    "                                                                     gw.world_size[1]-1), 5, 4),\n",
    "                                             IntSdrEncoder('direction', 4, 5, 4)],\n",
    "                                   size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_encoder.value_bits)\n",
    "state_encoder.total_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder = IntSdrEncoder('action', gw.n_actions,\n",
    "                              value_bits=6, activation_threshold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder = SaSdrEncoder(state_encoder, action_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder.total_bits, sa_encoder.value_bits, sa_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder.value_bits ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TemporalMemory(n_columns=sa_encoder.total_bits,\n",
    "                    cells_per_column=8,\n",
    "                    activation_threshold=sa_encoder.activation_threshold,\n",
    "                    learning_threshold=sa_encoder.activation_threshold,\n",
    "                    initial_permanence=0.5,\n",
    "                    connected_permanence=0.5,\n",
    "                    maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                    maxSynapsesPerSegment=sa_encoder.value_bits*2,\n",
    "                    permanenceIncrement=0.1,\n",
    "                    permanenceDecrement=0.02,\n",
    "                    predictedSegmentDecrement=0.001\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.activation_threshold, sa_encoder.value_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.getMaxSegmentsPerCell(), tm.getMaxNewSynapseCount(), tm.getMaxSynapsesPerSegment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(tm, sa_encoder, sa_encoder.format, format_sa_superposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_basic = [2, 2, 1, 2, 2, 1, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(actions, temporal_memory, environment, verbosity=1, n_cycles=3, with_reset=False):\n",
    "    for i in range(n_cycles):\n",
    "        if with_reset:\n",
    "            temporal_memory.reset()\n",
    "        if verbosity>1:\n",
    "            print()\n",
    "            print(f'*** cycle {i+1} ***')\n",
    "            print()\n",
    "        state, reward, done = environment.reset(), 0, False\n",
    "        for action in actions:\n",
    "            if verbosity > 1:\n",
    "                environment.render()\n",
    "                print(f'Action {action} State: {state}')\n",
    "            temporal_memory.train(Sa(state, action), verbosity)\n",
    "            state, _, _, info = environment.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(actions_basic, memory, gw, n_cycles=3, verbosity=3, with_reset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем воспроизвести ситуацию, когда память не может предсказать последовательность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TemporalMemory(n_columns=sa_encoder.total_bits,\n",
    "                    cells_per_column=8,\n",
    "                    activation_threshold=sa_encoder.activation_threshold,\n",
    "                    learning_threshold=action_encoder.activation_threshold,\n",
    "                    initial_permanence=0.5,\n",
    "                    connected_permanence=0.5,\n",
    "                    maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                    maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                    permanenceIncrement=0.1,\n",
    "                    permanenceDecrement=0,\n",
    "                    predictedSegmentDecrement=0\n",
    "                    )\n",
    "memory = Memory(tm, sa_encoder, sa_encoder.format, format_sa_superposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(actions_basic, memory, gw, verbosity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пытаемся объяснить, почему так происходит.\n",
    "\n",
    "За что отвечает learning_threshold?\n",
    "\n",
    "learning_threshold = minThreshold\n",
    "\n",
    "minThreshold это минимальное количество активных синапсов сегмента при котором будет происходить их обучение.\n",
    "\n",
    "Посмотрим, как изменится ситуация, если начальное знанчение permanence сделать заведомо больше чем нужно\n",
    "для соединения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TemporalMemory(n_columns=sa_encoder.total_bits,\n",
    "                    cells_per_column=8,\n",
    "                    activation_threshold=sa_encoder.activation_threshold,\n",
    "                    learning_threshold=action_encoder.activation_threshold,\n",
    "                    initial_permanence=1,\n",
    "                    connected_permanence=0.5,\n",
    "                    maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                    maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                    permanenceIncrement=0.1,\n",
    "                    permanenceDecrement=0,\n",
    "                    predictedSegmentDecrement=0\n",
    "                    )\n",
    "memory = Memory(tm, sa_encoder, sa_encoder.format, format_sa_superposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(actions_basic, memory, gw, verbosity=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ситуация не изменилась. Возможно, есть ещё параметры, которые могут влиять на permanence.\n",
    "В противном случае непонятно, почему последовательность не запоминается.\n",
    "\n",
    "Установим learning_threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TemporalMemory(n_columns=sa_encoder.total_bits,\n",
    "                    cells_per_column=8,\n",
    "                    activation_threshold=sa_encoder.activation_threshold,\n",
    "                    learning_threshold=0,\n",
    "                    initial_permanence=0.5,\n",
    "                    connected_permanence=0.5,\n",
    "                    maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                    maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                    permanenceIncrement=0.0,\n",
    "                    permanenceDecrement=0.0,\n",
    "                    predictedSegmentDecrement=0.0\n",
    "                    )\n",
    "memory = Memory(tm, sa_encoder, sa_encoder.format, format_sa_superposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test(actions_basic, memory, gw, verbosity=3, n_cycles=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.printParameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В крайнем случае, когда learning_threshold=0, выигрывают одни и те же клетки, которые уже имеют сегменты. Это понятно\n",
    "из алгоритма. Однако пока непонятно, почему алгоритм каждый раз создаёт новые синапсы и дропает предыдущие. По идее,\n",
    "он должен просто реинфорсить старые синапсы и наращивать новые, если слоты ещё не заполнены.\n",
    "\n",
    "Из кода на github понятно, что в случае, если не хватает слотов,\n",
    "то удаляют синапсы с наименьшим permanence, чтобы освобоить место для\n",
    "новых синапсов. Но всё же не ясно, как так получается, что nGrowDesired>0 (`#228, Temporal_Memory.cpp`).\n",
    "\n",
    "`nGrowDesired = maxNewSynapseCount_ - numActivePotentialSynapsesForSegment_[*bestMatchingSegment]`\n",
    "\n",
    "Итак, вероятно, где-то баг или я не так что-то понял, но суть проблемы в том, что когда у нас learning_threshold=0 и\n",
    "sdr сильно перекрываются, т.е. меняются мало, то на каджом шаге часто активируются одни и те же колонки,\n",
    "среди которых выбираются одни и те же клетки, т.к. они все имеют достаточно потенциально активных сегментов\n",
    "в силу условия learning_threshold=0. Баг в том, что\n",
    "по идее, эти выбранные сегменты просто должны реинфорсить свои синапсы или наказывать их, и т.к. все слоты уже заняты,\n",
    "число новых синапсов должно быть равным нулю, но на деле, получается, что выращиваются новые синапсы, которые переподключаются\n",
    "к новым клеткам, а старые синапсы удаляются. Такие клетки никогда не смогут выучить свой контекст. Из кода следует, что если число\n",
    "потенциальных синапсов с активной предсинаптической клеткой меньше максимально добавляемого числа синапсов,\n",
    "то будут выращены новые синапсы,\n",
    "причём, если им не хватает слотов на сегменте, то будут удалены старые, наименее активные синапсы, с наименьшим permanence.\n",
    "Что здесь и происходит. Т.к. не все предсинаптические клетки сегмента активны в силу того, что sdr всё-таки разные, то вот эта\n",
    "неактивная часть синапсов будет перезаписана новыми синапсами. То есть, как раз та часть перезапишется, которая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
