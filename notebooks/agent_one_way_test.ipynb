{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htm_rl.agent.agent import Agent, AgentRunner\n",
    "from htm_rl.agent.memory import Memory, TemporalMemory\n",
    "from htm_rl.agent.planner import Planner\n",
    "from htm_rl.common.sa_sdr_encoder import SaSdrEncoder, format_sa_superposition\n",
    "from htm_rl.common.base_sa import SaRelatedComposition, Sa, SaSuperposition\n",
    "from htm_rl.common.int_sdr_encoder import IntSdrEncoder, IntRangeEncoder\n",
    "from htm_rl.common.int_sdr_encoder import SequenceSdrEncoder\n",
    "from htm_rl.envs.gridworld_pomdp import GridWorld\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_description = [[2,0,0],\n",
    "                     [1,1,0],\n",
    "                     [0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = GridWorld(world_description, (3, 3), agent_initial_position={'row': 2, 'column': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 12\n",
    "\n",
    "state_encoder = SequenceSdrEncoder('state',\n",
    "                                   encoders=[IntSdrEncoder('distance',\n",
    "                                                                   gw.world_size[0],\n",
    "                                                                   5,\n",
    "                                                                   5),\n",
    "                                             IntSdrEncoder('surface', 3, 5, 5),\n",
    "                                             IntRangeEncoder('row', (-(gw.world_size[0]-1),\n",
    "                                                                     gw.world_size[1]-1), 5, 5),\n",
    "                                             IntRangeEncoder('column', (-(gw.world_size[0]-1),\n",
    "                                                                     gw.world_size[1]-1), 5, 5),\n",
    "                                             IntSdrEncoder('direction', 4, 5, 5)],\n",
    "                                   size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_encoder.value_bits)\n",
    "state_encoder.total_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder = IntSdrEncoder('action', gw.n_actions,\n",
    "                              value_bits=5, activation_threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder = SaSdrEncoder(state_encoder, action_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder.total_bits, sa_encoder.value_bits, sa_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TemporalMemory(n_columns=sa_encoder.total_bits,\n",
    "                    cells_per_column=16,\n",
    "                    activation_threshold=sa_encoder.value_bits,\n",
    "                    learning_threshold=sa_encoder.value_bits,\n",
    "                    initial_permanence=0.5,\n",
    "                    connected_permanence=0.5,\n",
    "                    maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                    maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                    permanenceIncrement=0.1,\n",
    "                    permanenceDecrement=0.005,\n",
    "                    predictedSegmentDecrement=0.0001\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(tm, sa_encoder, sa_encoder.format, format_sa_superposition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальный путь (ахах, самоуверенный человек, думает, что он нашёл оптимальный путь)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [2, 2, 1, 2, 2, 1, 2, 2]\n",
    "goal_state = (0, 2, -2, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем случайные пути и добавим один правильный путь. Проверим, сколько случайных путей нужно добавить,\n",
    "чтобы планирование сломалось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_memory(pars, sa_encoder, start_indicator=None):\n",
    "    tm = TemporalMemory(**pars)\n",
    "    memory = Memory(tm, sa_encoder, sa_encoder.format, format_sa_superposition, start_indicator=start_indicator)\n",
    "    return memory\n",
    "\n",
    "def learn_way(way, memory, environment, verbosity=1):\n",
    "    memory.reset()\n",
    "    state, reward, done = environment.reset(), 0, False\n",
    "    for action in way:\n",
    "        if verbosity > 1:\n",
    "            environment.render()\n",
    "            print(f'Action {action} State: {state}')\n",
    "        memory.train(Sa(state, action), verbosity)\n",
    "        state, _, _, info = environment.step(action)\n",
    "\n",
    "def check_agent(memory, environment, goal_state, verbosity=1):\n",
    "    planner = Planner(memory, 10, 1)\n",
    "    agent = Agent(memory, planner, environment.n_actions)\n",
    "    run = AgentRunner(agent, environment, 1, max_steps, 0, verbosity)\n",
    "    run.agent.planner.add_goal(goal_state)\n",
    "    run.agent.set_planning_horizon(10)\n",
    "    run.run()\n",
    "    if run.train_stats.rewards[-1] > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_way(max_steps, n_actions):\n",
    "    return [randint(0, n_actions-1) for _ in range(max_steps)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учим агент оптимальному пути, потом добавляем постепенно случайные пути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = init_memory(pars=dict(n_columns=sa_encoder.total_bits,\n",
    "                                cells_per_column=8,\n",
    "                                activation_threshold=sa_encoder.value_bits,\n",
    "                                learning_threshold=sa_encoder.value_bits,\n",
    "                                initial_permanence=0.5,\n",
    "                                connected_permanence=0.5,\n",
    "                                maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                                maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                                permanenceIncrement=0.1,\n",
    "                                permanenceDecrement=0.005,\n",
    "                                predictedSegmentDecrement=0.0001), sa_encoder=sa_encoder)\n",
    "learn_way(actions, memory, gw)\n",
    "ways_history = list()\n",
    "ways_history.append(actions)\n",
    "\n",
    "while check_agent(memory, gw, goal_state):\n",
    "    way = random_way(max_steps, gw.n_actions)\n",
    "    ways_history.append(way)\n",
    "    learn_way(way, memory, gw)\n",
    "\n",
    "print('Steps:', len(ways_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = check_agent(memory, gw, goal_state, verbosity=-1)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_way_before_experiments(memory_pars, sa_encoder, goal_state, n_experiments=3, verbosity=0):\n",
    "    results = list()\n",
    "    for _ in tqdm(range(n_experiments)):\n",
    "        memory = init_memory(memory_pars, sa_encoder)\n",
    "        learn_way(actions, memory, gw)\n",
    "        ways_history = list()\n",
    "        ways_history.append(actions)\n",
    "        while check_agent(memory, gw, goal_state, verbosity=verbosity):\n",
    "            way = random_way(max_steps, gw.n_actions)\n",
    "            ways_history.append(way)\n",
    "            learn_way(way, memory, gw)\n",
    "        results.append({'steps': len(ways_history)})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = dict(n_columns=sa_encoder.total_bits,\n",
    "                                cells_per_column=32,\n",
    "                                activation_threshold=sa_encoder.value_bits,\n",
    "                                learning_threshold=sa_encoder.value_bits,\n",
    "                                initial_permanence=0.5,\n",
    "                                connected_permanence=0.5,\n",
    "                                maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                                maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                                permanenceIncrement=0.1,\n",
    "                                permanenceDecrement=0.005,\n",
    "                                predictedSegmentDecrement=0.0001)\n",
    "results = run_way_before_experiments(pars, n_experiments=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "df_results.steps.mean(), df_results.steps.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим зависимость устойчивости трекера от числа клеток в колонке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict(steps_av=[], steps_err=[], n_experiments=[], n_cols=[], elapsed_time=[])\n",
    "for n_cols in [8, 16, 32, 50, 70]:\n",
    "    n_experiments = 10\n",
    "    start = time.time()\n",
    "    pars = dict(n_columns=sa_encoder.total_bits,\n",
    "                                    cells_per_column=n_cols,\n",
    "                                    activation_threshold=sa_encoder.value_bits,\n",
    "                                    learning_threshold=sa_encoder.value_bits,\n",
    "                                    initial_permanence=0.5,\n",
    "                                    connected_permanence=0.5,\n",
    "                                    maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                                    maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                                    permanenceIncrement=0.1,\n",
    "                                    permanenceDecrement=0.005,\n",
    "                                    predictedSegmentDecrement=0.0001)\n",
    "    result = run_way_before_experiments(pars, sa_encoder, goal_state, n_experiments=n_experiments)\n",
    "    end = time.time()\n",
    "\n",
    "    elapsed_time = end - start\n",
    "\n",
    "    df_results = pd.DataFrame(result)\n",
    "    steps_mean, steps_std = df_results.steps.mean(), df_results.steps.std()\n",
    "\n",
    "    results['steps_av'].append(steps_mean)\n",
    "    results['steps_err'].append(steps_std)\n",
    "    results['elapsed_time'].append(elapsed_time)\n",
    "    results['n_cols'].append(n_cols)\n",
    "    results['n_experiments'].append(n_experiments)\n",
    "    print(f'{n_cols:2d} --> done {elapsed_time/60:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols_test_results = pd.DataFrame(results)\n",
    "n_cols_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(n_cols_test_results['n_cols'],\n",
    "             n_cols_test_results['steps_av'], yerr=n_cols_test_results['steps_err'], fmt='*', capsize=5)\n",
    "plt.ylabel('number of noise ways')\n",
    "plt.xlabel('number of cells in column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим влияние числа синапсов на сегмент на устойчивость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict(steps_av=[], steps_err=[], n_experiments=[], n_synapses=[], elapsed_time=[])\n",
    "for n_synapses in [5, 10, 20, 25, 50, 100]:\n",
    "    n_experiments = 10\n",
    "    start = time.time()\n",
    "    pars = dict(n_columns=sa_encoder.total_bits,\n",
    "                                    cells_per_column=50,\n",
    "                                    activation_threshold=sa_encoder.value_bits,\n",
    "                                    learning_threshold=sa_encoder.value_bits,\n",
    "                                    initial_permanence=0.5,\n",
    "                                    connected_permanence=0.5,\n",
    "                                    maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                                    maxSynapsesPerSegment=(sa_encoder.value_bits + n_synapses),\n",
    "                                    permanenceIncrement=0.1,\n",
    "                                    permanenceDecrement=0.005,\n",
    "                                    predictedSegmentDecrement=0.0001)\n",
    "    result = run_way_before_experiments(pars, sa_encoder, goal_state, n_experiments=n_experiments)\n",
    "    end = time.time()\n",
    "\n",
    "    elapsed_time = end - start\n",
    "\n",
    "    df_results = pd.DataFrame(result)\n",
    "    steps_mean, steps_std = df_results.steps.mean(), df_results.steps.std()\n",
    "\n",
    "    results['steps_av'].append(steps_mean)\n",
    "    results['steps_err'].append(steps_std)\n",
    "    results['elapsed_time'].append(elapsed_time)\n",
    "    results['n_synapses'].append(n_synapses + sa_encoder.value_bits)\n",
    "    results['n_experiments'].append(n_experiments)\n",
    "    print(f'{n_cols:2d} --> done {elapsed_time/60:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_synapses_test_results = pd.DataFrame(results)\n",
    "n_synapses_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим влияние learning_threshold на устойчивость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict(steps_av=[], steps_err=[], n_experiments=[], learning_threshold=[], elapsed_time=[])\n",
    "for threshold in [1, 2, 3, 4, 5, 6, 10, 15, 25, sa_encoder.value_bits]:\n",
    "    n_experiments = 10\n",
    "    start = time.time()\n",
    "    pars = dict(n_columns=sa_encoder.total_bits,\n",
    "                                    cells_per_column=50,\n",
    "                                    activation_threshold=sa_encoder.value_bits,\n",
    "                                    learning_threshold=(sa_encoder.value_bits - threshold),\n",
    "                                    initial_permanence=0.5,\n",
    "                                    connected_permanence=0.5,\n",
    "                                    maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                                    maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                                    permanenceIncrement=0.1,\n",
    "                                    permanenceDecrement=0.005,\n",
    "                                    predictedSegmentDecrement=0.0001)\n",
    "    result = run_way_before_experiments(pars, sa_encoder, goal_state, n_experiments=n_experiments)\n",
    "    end = time.time()\n",
    "\n",
    "    elapsed_time = end - start\n",
    "\n",
    "    df_results = pd.DataFrame(result)\n",
    "    steps_mean, steps_std = df_results.steps.mean(), df_results.steps.std()\n",
    "\n",
    "    results['steps_av'].append(steps_mean)\n",
    "    results['steps_err'].append(steps_std)\n",
    "    results['elapsed_time'].append(elapsed_time)\n",
    "    results['learning_threshold'].append(sa_encoder.value_bits - threshold)\n",
    "    results['n_experiments'].append(n_experiments)\n",
    "    print(f'{sa_encoder.value_bits - threshold:2d} --> done {elapsed_time/60:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_threshold_test_results = pd.DataFrame(results)\n",
    "learning_threshold_test_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сначала кормим случайные последовательности и в конце даём правильную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def way_to_string(way):\n",
    "    res = str()\n",
    "    for action in way:\n",
    "        res+=str(action)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_way_after_experiments(pars, sa_encoder, goal_state,\n",
    "                              start_indicator=None,\n",
    "                              n_experiments=3,\n",
    "                              verbosity=0,\n",
    "                              learning_true_count=1):\n",
    "    results = list()\n",
    "    ways_history = {'way': [], 'steps': [], 'experiment': []}\n",
    "    for experiment in tqdm(range(n_experiments)):\n",
    "        n_steps = 0 # number of noise action sequences\n",
    "        while True:\n",
    "            memory = init_memory(pars, sa_encoder, start_indicator=start_indicator)\n",
    "            way = None\n",
    "            for step in range(n_steps):\n",
    "                way = random_way(max_steps, gw.n_actions)\n",
    "                learn_way(way, memory, gw)\n",
    "            for _ in range(learning_true_count):\n",
    "                learn_way(actions, memory, gw)\n",
    "            if not check_agent(memory, gw, goal_state, verbosity):\n",
    "                if way is not None:\n",
    "                    ways_history['way'].append(str(way))\n",
    "                    ways_history['steps'].append(n_steps)\n",
    "                    ways_history['experiment'].append(experiment)\n",
    "                break\n",
    "            else:\n",
    "                n_steps += 1\n",
    "        results.append(n_steps)\n",
    "    return results, ways_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_state = (0, 2, -2, 1, 2)\n",
    "pars = dict(n_columns=sa_encoder.total_bits,\n",
    "                                cells_per_column=50,\n",
    "                                activation_threshold=sa_encoder.value_bits,\n",
    "                                learning_threshold=sa_encoder.value_bits,\n",
    "                                initial_permanence=0.5,\n",
    "                                connected_permanence=0.5,\n",
    "                                maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                                maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                                permanenceIncrement=0.1,\n",
    "                                permanenceDecrement=0.005,\n",
    "                                predictedSegmentDecrement=0.0001)\n",
    "results, ways_history = run_way_after_experiments(pars, sa_encoder, goal_state, n_experiments=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = np.array(results)\n",
    "df_results.mean(), df_results.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ways = pd.DataFrame(ways_history)\n",
    "df_ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ways[df_ways['steps'] == df_ways.steps.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways_counts = df_ways.way.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways_counts.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "Теперь оставим в кодировке только координаты и проверим устойчивость снова ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = GridWorld(world_description, (3, 3), agent_initial_position={'row': 2, 'column': 0},\n",
    "               observable_vars=['relative_row', 'relative_column', 'relative_direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.observable_state, gw.filtered_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_encoder = SequenceSdrEncoder('state',\n",
    "                                   encoders=[\n",
    "                                             IntRangeEncoder('row', (-(gw.world_size[0]-1),\n",
    "                                                                     gw.world_size[1]-1), 5, 5),\n",
    "                                             IntRangeEncoder('column', (-(gw.world_size[0]-1),\n",
    "                                                                     gw.world_size[1]-1), 5, 5),\n",
    "                                             IntSdrEncoder('direction', 4, 5, 5)],\n",
    "                                   size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder = IntSdrEncoder('action', gw.n_actions,\n",
    "                              value_bits=5, activation_threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder = SaSdrEncoder(state_encoder, action_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder.total_bits, sa_encoder.value_bits, sa_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_state = (-2, 1, 2)\n",
    "pars = dict(n_columns=sa_encoder.total_bits,\n",
    "                                cells_per_column=50,\n",
    "                                activation_threshold=sa_encoder.value_bits,\n",
    "                                learning_threshold=sa_encoder.value_bits,\n",
    "                                initial_permanence=0.5,\n",
    "                                connected_permanence=0.5,\n",
    "                                maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                                maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                                permanenceIncrement=0.1,\n",
    "                                permanenceDecrement=0.005,\n",
    "                                predictedSegmentDecrement=0.0001)\n",
    "results = run_way_after_experiments(pars, sa_encoder, goal_state, n_experiments=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = np.array(results)\n",
    "df_results.mean(), df_results.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь оставим только расстояние и тип поверхности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = GridWorld(world_description, (3, 3), agent_initial_position={'row': 2, 'column': 0},\n",
    "               observable_vars=['distance', 'surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.observable_state, gw.filtered_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_encoder = SequenceSdrEncoder('state',\n",
    "                                   encoders=[\n",
    "                                             IntSdrEncoder('distance',\n",
    "                                                                   gw.world_size[0] + 1,\n",
    "                                                                   5,\n",
    "                                                                   5),\n",
    "                                             IntSdrEncoder('surface', 3 + 1, 5, 5)\n",
    "                                            ],\n",
    "                                   size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder = IntSdrEncoder('action', gw.n_actions + 1,\n",
    "                              value_bits=5, activation_threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder = SaSdrEncoder(state_encoder, action_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder.total_bits, sa_encoder.value_bits, sa_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_state = (0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = dict(n_columns=sa_encoder.total_bits,\n",
    "                                cells_per_column=50,\n",
    "                                activation_threshold=sa_encoder.value_bits,\n",
    "                                learning_threshold=sa_encoder.value_bits,\n",
    "                                initial_permanence=0.5,\n",
    "                                connected_permanence=0.5,\n",
    "                                maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                                maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                                permanenceIncrement=0.1,\n",
    "                                permanenceDecrement=0.005,\n",
    "                                predictedSegmentDecrement=0.0001)\n",
    "results = run_way_after_experiments(pars, sa_encoder, goal_state, n_experiments=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = np.array(results[0])\n",
    "df_results.mean(), df_results.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = dict(n_columns=sa_encoder.total_bits,\n",
    "                                cells_per_column=8,\n",
    "                                activation_threshold=sa_encoder.value_bits,\n",
    "                                learning_threshold=sa_encoder.value_bits,\n",
    "                                initial_permanence=0.5,\n",
    "                                connected_permanence=0.5,\n",
    "                                maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                                maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                                permanenceIncrement=0.1,\n",
    "                                permanenceDecrement=0.05,\n",
    "                                predictedSegmentDecrement=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbosity=0\n",
    "fails = list()\n",
    "for i in tqdm(range(100)):\n",
    "    memory = init_memory(pars, sa_encoder)\n",
    "    learn_way(actions, memory, gw, verbosity)\n",
    "    fails.append(check_agent(memory, gw, goal_state, verbosity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(fails, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ввели состояние - индикатор начала последовательности. Теперь, сразу после ресета TM обрабатывает индикаторное состояние.\n",
    "Также пришлось увеличить predictedSegmentDecrement, чтобы последовательность могла достаточно быстро выучивать контекст,\n",
    "однако, пока неизвестно, как это скажется на работе агента в полевых условиях. Теперь, по крайней мере, агент может находить\n",
    "путь к награде при отсутствии шумовых последовательностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = dict(n_columns=sa_encoder.total_bits,\n",
    "                                cells_per_column=8,\n",
    "                                activation_threshold=sa_encoder.value_bits,\n",
    "                                learning_threshold=sa_encoder.value_bits,\n",
    "                                initial_permanence=0.5,\n",
    "                                connected_permanence=0.5,\n",
    "                                maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                                maxSynapsesPerSegment=sa_encoder.value_bits,\n",
    "                                permanenceIncrement=0.1,\n",
    "                                permanenceDecrement=0.05,\n",
    "                                predictedSegmentDecrement=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 12\n",
    "verbosity = 3\n",
    "memory = init_memory(pars, sa_encoder, start_indicator=Sa((3, 3), 3))\n",
    "for _ in range(9):\n",
    "    learn_way(actions, memory, gw, verbosity=1)\n",
    "learn_way(actions, memory, gw, verbosity)\n",
    "check_agent(memory, gw, goal_state, verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_way_after_experiments(pars, sa_encoder, goal_state,\n",
    "                                    start_indicator=Sa((3, 3), 3),\n",
    "                                    n_experiments=100,\n",
    "                                    learning_true_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = np.array(results[0])\n",
    "df_results.mean(), df_results.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_way_after_experiments(pars, sa_encoder, goal_state,\n",
    "                                    start_indicator=Sa((3, 3), 3),\n",
    "                                    n_experiments=100,\n",
    "                                    learning_true_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = np.array(results[0])\n",
    "df_results.mean(), df_results.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описать пример, на основе которого я решил увеличить predictedSegmentDecrement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_encoders(value_bits, thresholds):\n",
    "    state_encoder = SequenceSdrEncoder('state',\n",
    "                                   encoders=[IntSdrEncoder('distance',\n",
    "                                                                   gw.world_size[0],\n",
    "                                                                   value_bits[0],\n",
    "                                                                   thresholds[0]),\n",
    "                                             IntSdrEncoder('surface', 3, value_bits[1], thresholds[1]),\n",
    "                                             IntRangeEncoder('row', (-(gw.world_size[0]-1),\n",
    "                                                                     gw.world_size[1]-1), value_bits[2], thresholds[2]),\n",
    "                                             IntRangeEncoder('column', (-(gw.world_size[0]-1),\n",
    "                                                                     gw.world_size[1]-1), value_bits[3], thresholds[3]),\n",
    "                                             IntSdrEncoder('direction', 4, value_bits[4], thresholds[4])],\n",
    "                                   size=5)\n",
    "    action_encoder = IntSdrEncoder('action', gw.n_actions,\n",
    "                              value_bits=value_bits[5], activation_threshold=thresholds[5])\n",
    "    return state_encoder, action_encoder\n",
    "\n",
    "def stability_test(pars):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ручной вариант(изначальный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways = [\n",
    "    [2, 2, 1, 2, 2, 1, 2, 2],\n",
    "    [1, 0, 2, 2, 1, 2, 2, 1, 2, 1, 0, 2],\n",
    "    [2, 2, 1, 1, 2, 2, 0, 0],\n",
    "    [2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1],\n",
    "    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "    [2, 2, 1, 2, 2, 1, 0, 2, 2, 2, 2, 2],\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "       ]\n",
    "\n",
    "actions = [2, 2, 1, 2, 2, 1, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbosity = 1\n",
    "for i, way in enumerate(ways):\n",
    "    if verbosity>1:\n",
    "        print()\n",
    "        print(f\"### Way {i+1} ###\")\n",
    "        print()\n",
    "    for i in range(2):\n",
    "        if verbosity>1:\n",
    "            print()\n",
    "            print(f'*** cycle {i+1} ***')\n",
    "            print()\n",
    "        memory.reset()\n",
    "        state, reward, done = gw.reset(), 0, False\n",
    "        for action in way:\n",
    "            if verbosity > 1:\n",
    "                gw.render()\n",
    "                print(f'Action {action} State: {state}')\n",
    "            memory.train(Sa(state, action), verbosity)\n",
    "            state, _, _, info = gw.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_state = (0, 2, -2, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = Planner(memory, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(memory, planner, gw.n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = AgentRunner(agent, gw, 1, max_steps, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.agent.planner.add_goal(goal_state)\n",
    "run.agent.set_planning_horizon(10)\n",
    "run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.train_stats.rewards[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка стабильности обратного трекинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.agent.planner.add_goal(goal_state)\n",
    "run.agent.set_planning_horizon(10)\n",
    "run.n_episodes = 50\n",
    "run.pretrain = 25\n",
    "run.verbosity = 1\n",
    "run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "steps = np.array(run.train_stats.steps[:])\n",
    "plt.plot(np.arange(steps.size), steps, '.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
