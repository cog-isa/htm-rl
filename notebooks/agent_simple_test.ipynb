{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../htm_rl/htm_rl/')\n",
    "\n",
    "from agent.agent import Agent, AgentRunner\n",
    "from agent.memory import Memory, TemporalMemory\n",
    "from agent.planner import Planner\n",
    "from envs.mdp import Mdp\n",
    "from common.sa_sdr_encoder import SaSdrEncoder, format_sa_superposition\n",
    "from common.int_sdr_encoder import IntSdrEncoder, IntSdrFormatter\n",
    "from common.int_sdr_encoder import SequenceSdrEncoder, IntSemanticSdrEncoder\n",
    "from envs.mymdp import GridWorld\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic example for standard MDP environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp = Mdp(transitions = {\n",
    "            0: {0: 4, 1: 1},\n",
    "            1: {0: 1, 1: 2},\n",
    "            2: {0: 2, 1: 3},\n",
    "            3: {0: 3, 1: 0},\n",
    "            4: None\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdp.n_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_encoder = IntSdrEncoder('state',\n",
    "                              n_values=mdp.n_states,\n",
    "                              value_bits=10,\n",
    "                              activation_threshold=7)\n",
    "\n",
    "\n",
    "action_encoder = IntSdrEncoder('action',\n",
    "                               n_values=mdp.n_actions,\n",
    "                               value_bits=10,\n",
    "                               activation_threshold=7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder = SaSdrEncoder(state_encoder, action_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder.total_bits\n",
    "sa_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TemporalMemory(n_columns=sa_encoder.total_bits,\n",
    "                    cells_per_column=1,\n",
    "                    activation_threshold=sa_encoder.activation_threshold,\n",
    "                    learning_threshold=action_encoder.activation_threshold,\n",
    "                    initial_permanence=0.49,\n",
    "                    connected_permanence=0.5,\n",
    "                    maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                    maxSynapsesPerSegment=sa_encoder.value_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_formatter = IntSdrFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(tm, sa_encoder, sa_formatter, sa_encoder.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = Planner(memory,\n",
    "                  planning_horizon=10,\n",
    "                  goal_memory_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(memory, planner, mdp.n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = AgentRunner(agent, mdp,\n",
    "                  n_episodes=100,\n",
    "                  max_steps=10,\n",
    "                  pretrain=50,\n",
    "                  verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Agent in gridworld environment with two-value state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_description = [[2,0,0,0,0],\n",
    "                     [1,1,1,0,0],\n",
    "                     [0,0,0,0,1],\n",
    "                     [1,1,0,0,0],\n",
    "                     [0,0,0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = GridWorld(world_description, (5, 5), agent_initial_position={'row': 4, 'column': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_encoder = SequenceSdrEncoder('state', encoders=[IntSdrEncoder('distance', gw.world_size[0]+1, 10, 7),\n",
    "                                                   IntSdrEncoder('surface', 3, 10, 7)],\n",
    "                                size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_encoder.value_bits)\n",
    "state_encoder.total_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder = IntSdrEncoder('action', 3,\n",
    "                              value_bits=10, activation_threshold=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder = SaSdrEncoder(state_encoder, action_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TemporalMemory(n_columns=sa_encoder.total_bits,\n",
    "                    cells_per_column=2,\n",
    "                    activation_threshold=sa_encoder.activation_threshold,\n",
    "                    learning_threshold=action_encoder.activation_threshold,\n",
    "                    initial_permanence=0.49,\n",
    "                    connected_permanence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_formatter = IntSdrFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(tm, sa_encoder, sa_formatter, format_sa_superposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = Planner(memory, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(memory, planner, gw.n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = AgentRunner(agent, gw, 5, 10, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of agent in two-value-state environment with semantic encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_description = [[2,0,0],\n",
    "                     [1,1,0],\n",
    "                     [0,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw = GridWorld(world_description, (3, 3), agent_initial_position={'row': 2, 'column': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_encoder = SequenceSdrEncoder('state',\n",
    "                                   encoders=[IntSdrEncoder('distance',\n",
    "                                                                   gw.world_size[0],\n",
    "                                                                   3,\n",
    "                                                                   2),\n",
    "                                                   IntSdrEncoder('surface', 3, 3, 2)],\n",
    "                                   size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_encoder.value_bits)\n",
    "state_encoder.total_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder = IntSdrEncoder('action', gw.n_actions,\n",
    "                              value_bits=6, activation_threshold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder = SaSdrEncoder(state_encoder, action_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_encoder.total_bits, sa_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_encoder.activation_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = TemporalMemory(n_columns=sa_encoder.total_bits,\n",
    "                    cells_per_column=8,\n",
    "                    activation_threshold=sa_encoder.activation_threshold,\n",
    "                    learning_threshold=action_encoder.activation_threshold,\n",
    "                    initial_permanence=0.45,\n",
    "                    connected_permanence=0.5,\n",
    "                    maxNewSynapseCount=sa_encoder.value_bits,\n",
    "                    maxSynapsesPerSegment=sa_encoder.value_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.activation_threshold, tm.connected_permanence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.getMaxSegmentsPerCell(), tm.getMaxNewSynapseCount(), tm.getMaxSynapsesPerSegment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr_formatter = IntSdrFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(tm, sa_encoder, sa_encoder.format, format_sa_superposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = Planner(memory, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner.planning_horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(memory, planner, gw.n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent._planning_horizon, agent._planning_enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = AgentRunner(agent, gw, 10000, 12, 10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.agent.planner.inter_episode_goal_memory._set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.agent.set_planning_horizon(10)\n",
    "run.max_steps = 12\n",
    "run.verbosity = 1\n",
    "run.pretrain = 0\n",
    "run.n_episodes = 10\n",
    "run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.agent.set_planning_horizon(10)\n",
    "run.max_steps = 10\n",
    "run.verbosity = 3\n",
    "run.pretrain = 0\n",
    "run.n_episodes = 1\n",
    "run.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "steps = np.array(run.train_stats.steps[10000:])\n",
    "plt.plot(np.arange(steps.size), steps, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.mean(), steps.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7))\n",
    "steps = np.array(run.train_stats.rewards[10000:])\n",
    "plt.plot(np.arange(steps.size), steps, '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
