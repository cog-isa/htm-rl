@article{Brown_Sandholm_2017_Poker,
  title     = {Superhuman AI for heads-up no-limit poker: Libratus beats top professionals},
  volume    = {359},
  url       = {http://dx.doi.org/10.1126/science.aao1733},
  doi       = {10.1126/science.aao1733},
  number    = {6374},
  journal   = {Science},
  publisher = {American Association for the Advancement of Science (AAAS)},
  author    = {Brown, Noam and Sandholm, Tuomas},
  year      = {2017},
  month     = {Dec},
  pages     = {418–424}
}

@article{Campbell_Hoane_Hsu_2002_DeepBlue,
  title     = {Deep Blue},
  volume    = {134},
  url       = {http://dx.doi.org/10.1016/S0004-3702(01)00129-1},
  doi       = {10.1016/s0004-3702(01)00129-1},
  number    = {1–2},
  journal   = {Artificial Intelligence},
  publisher = {Elsevier BV},
  author    = {Campbell, Murray and Hoane, A.Joseph, Jr. and Hsu, Feng-hsiung},
  year      = {2002},
  month     = {Jan},
  pages     = {57–83}
}

@inbook{Coulom_2007_mcts,
  title     = {Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search},
  url       = {http://dx.doi.org/10.1007/978-3-540-75538-8\_7},
  doi       = {10.1007/978-3-540-75538-8\_7},
  booktitle = {Computers and Games},
  publisher = {Springer Berlin Heidelberg},
  author    = {Coulom, Rémi},
  year      = {2007},
  pages     = {72–83}
}

@article{Cui_Ahmad_Hawkins_2017_sdr,
  title     = {The HTM Spatial Pooler—A Neocortical Algorithm for Online Sparse Distributed Coding},
  volume    = {11},
  url       = {http://dx.doi.org/10.3389/fncom.2017.00111},
  doi       = {10.3389/fncom.2017.00111},
  journal   = {Frontiers in Computational Neuroscience},
  publisher = {Frontiers Media SA},
  author    = {Cui, Yuwei and Ahmad, Subutai and Hawkins, Jeff},
  year      = {2017},
  month     = {Nov}
}

@article{George_Hawkins_2009,
  title     = {Towards a Mathematical Theory of Cortical Micro-circuits},
  volume    = {5},
  url       = {http://dx.doi.org/10.1371/journal.pcbi.1000532},
  doi       = {10.1371/journal.pcbi.1000532},
  number    = {10},
  journal   = {PLoS Computational Biology},
  publisher = {Public Library of Science (PLoS)},
  author    = {George, Dileep and Hawkins, Jeff},
  editor    = {Friston, Karl J.},
  year      = {2009},
  month     = {Oct},
  pages     = {e1000532}
}

@article{Ha_Schmidhuber_2018_worldmodels,
  title        = {World Models},
  url          = {https://zenodo.org/record/1207631},
  doi          = {10.5281/ZENODO.1207631},
  abstractnote = {We explore building generative neural network models of popular reinforcement learning environments. Our <em>world model</em> can be trained quickly in an unsupervised manner to learn a compressed spatial and temporal representation of the environment. By using features extracted from the world model as inputs to an agent, we can train a very compact and simple policy that can solve the required task. We can even train our agent entirely inside of its own hallucinated dream generated by its world model, and transfer this policy back into the actual environment. An interactive version of this article is available at worldmodels.github.io.},
  journal      = {Zenodo},
  publisher    = {Zenodo},
  author       = {Ha, David and Schmidhuber, Jürgen},
  year         = {2018},
  month        = {Mar}
}

@misc{haarnoja_2018_sac,
  title         = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author        = {Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
  year          = {2018},
  eprint        = {1801.01290},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{Hassabis_2017_neuro,
  title     = {Neuroscience-Inspired Artificial Intelligence},
  volume    = {95},
  url       = {http://dx.doi.org/10.1016/j.neuron.2017.06.011},
  doi       = {10.1016/j.neuron.2017.06.011},
  number    = {2},
  journal   = {Neuron},
  publisher = {Elsevier BV},
  author    = {Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
  year      = {2017},
  month     = {Jul},
  pages     = {245–258}
}
@article{hawkins_TM,
  author   = {Hawkins, Jeff and Ahmad, Subutai},
  title    = {Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex},
  journal  = {Frontiers in Neural Circuits},
  volume   = {10},
  pages    = {23},
  year     = {2016},
  url      = {https://www.frontiersin.org/article/10.3389/fncir.2016.00023},
  doi      = {10.3389/fncir.2016.00023},
  issn     = {1662-5110},
  abstract = {Pyramidal neurons represent the majority of excitatory neurons in the neocortex. Each pyramidal neuron receives input from thousands of excitatory synapses that are segregated onto dendritic branches. The dendrites themselves are segregated into apical, basal, and proximal integration zones, which have different properties. It is a mystery how pyramidal neurons integrate the input from thousands of synapses, what role the different dendrites play in this integration, and what kind of network behavior this enables in cortical tissue. It has been previously proposed that non-linear properties of dendrites enable cortical neurons to recognize multiple independent patterns. In this paper we extend this idea in multiple ways. First we show that a neuron with several thousand synapses segregated on active dendrites can recognize hundreds of independent patterns of cellular activity even in the presence of large amounts of noise and pattern variation. We then propose a neuron model where patterns detected on proximal dendrites lead to action potentials, defining the classic receptive field of the neuron, and patterns detected on basal and apical dendrites act as predictions by slightly depolarizing the neuron without generating an action potential. By this mechanism, a neuron can predict its activation in hundreds of independent contexts. We then present a network model based on neurons with these properties that learns time-based sequences. The network relies on fast local inhibition to preferentially activate neurons that are slightly depolarized. Through simulation we show that the network scales well and operates robustly over a wide range of parameters as long as the network uses a sparse distributed code of cellular activations. We contrast the properties of the new network model with several other neural network models to illustrate the relative capabilities of each. We conclude that pyramidal neurons with thousands of synapses, active dendrites, and multiple integration zones create a robust and powerful sequence memory. Given the prevalence and similarity of excitatory neurons throughout the neocortex and the importance of sequence memory in inference and behavior, we propose that this form of sequence memory may be a universal property of neocortical tissue.}
}

@misc{kaiser_2020_modelbased,
  title         = {Model-Based Reinforcement Learning for Atari},
  author        = {Lukasz Kaiser and Mohammad Babaeizadeh and Piotr Milos and Blazej Osinski and Roy H Campbell and Konrad Czechowski and Dumitru Erhan and Chelsea Finn and Piotr Kozakowski and Sergey Levine and Afroz Mohiuddin and Ryan Sepassi and George Tucker and Henryk Michalewski},
  year          = {2020},
  eprint        = {1903.00374},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{Mnih_2015_Atari,
  title     = {Human-level control through deep reinforcement learning},
  volume    = {518},
  url       = {http://dx.doi.org/10.1038/nature14236},
  doi       = {10.1038/nature14236},
  number    = {7540},
  journal   = {Nature},
  publisher = {Springer Science and Business Media LLC},
  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and et al.},
  year      = {2015},
  month     = {Feb},
  pages     = {529–533}
}

@misc{moerland_2020_modelbased,
  title         = {Model-based Reinforcement Learning: A Survey},
  author        = {Thomas M. Moerland and Joost Broekens and Catholijn M. Jonker},
  year          = {2020},
  eprint        = {2006.16712},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{openai_2019_dota,
  title         = {Dota 2 with Large Scale Deep Reinforcement Learning},
  author        = {Christopher Berner and Greg Brockman and Brooke Chan and Vicki Cheung and Przemyslaw Debiak and Christy Dennison and David Farhi and Quirin Fischer and Shariq Hashme and Chris Hesse and Rafal Jozefowicz and Scott Gray and Catherine Olsson and Jakub Pachocki and Michael Petrov and Henrique Ponde de Oliveira Pinto and Jonathan Raiman and Tim Salimans and Jeremy Schlatter and Jonas Schneider and Szymon Sidor and Ilya Sutskever and Jie Tang and Filip Wolski and Susan Zhang},
  year          = {2019},
  eprint        = {1912.06680},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@book{Puterman_1994,
  title     = {Markov Decision Processes},
  author    = {Puterman, Martin},
  url       = {http://dx.doi.org/10.1002/9780470316887},
  doi       = {10.1002/9780470316887},
  journal   = {Wiley Series in Probability and Statistics},
  publisher = {John Wiley \& Sons, Inc.},
  year      = {1994},
  month     = {Apr}
}

@misc{schulman_2017_ppo,
  title         = {Proximal Policy Optimization Algorithms},
  author        = {John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  year          = {2017},
  eprint        = {1707.06347},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}


@misc{silver_2020_muzero,
  title         = {Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model},
  author        = {Julian Schrittwieser and Ioannis Antonoglou and Thomas Hubert and Karen Simonyan and Laurent Sifre and Simon Schmitt and Arthur Guez and Edward Lockhart and Demis Hassabis and Thore Graepel and Timothy Lillicrap and David Silver},
  year          = {2020},
  eprint        = {1911.08265},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{Silver_Go,
  title   = {Mastering the game of Go with deep neural networks and tree search},
  author  = {David Silver and Aja Huang and Christopher J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
  year    = {2016},
  url     = {http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html},
  journal = {Nature},
  pages   = {484--503},
  volume  = {529}
}

@article{Nugamanov2020,
abstract = {Nowadays our knowledge of the brain is actively getting wider. Hierarchical Temporal Memory is the technology that arose due to new discoveries in neurobiology, such as research on the structure of the neocortex. One of the most popular applications of this technology is image recognition and anomaly detection. Nevertheless, both in the neocortex and in hierarchical temporal memory technology is image recognition and anomaly detection. Nevertheless, both in the neocortex and in hierarchical temporal memory an image is recognized by its parts. Therefore, there is a problem of choosing the most meaningful parts of an image in order to perform fast and effective recognition. In this work we propose the architecture that unites Hierarchical Temporal Memory an image is recognized by its parts. Therefore, there is a problem of choosing the most meaningful parts of an image in order and Reinforcement Learning in order to find the optimal way of image exploration. Besides, we prove by experiments that this to perform fast and effective recognition. In this work we propose the architecture that unites Hierarchical Temporal Memory and Reinforcement Learning in order to find the optimal way of image exploration. Besides, we prove by experiments that this architecture is effective, and the quality of the resulting movement pattern is high. architecture is effective, and the quality of the resulting movement pattern is high.},
author = {Nugamanov, Eduard and Panov, Aleksandr I},
doi = {10.1016/j.procs.2020.02.123},
file = {:C$\backslash$:/Users/panov/OneDrive/Documents/Mendeley Desktop/2020/Nugamanov, Panov/2020 - Nugamanov, Panov.pdf:pdf},
journal = {Procedia Computer Science},
keywords = {18-29-22047,frccsc,hierarchical temporal memory,image recognition,mipt,monte carlo control,reinforcement learning,scopus},
mendeley-groups = {my{\_}publications},
mendeley-tags = {18-29-22047,frccsc,mipt,scopus},
pages = {123--131},
title = {{Hierarchical Temporal Memory with Reinforcement Learning}},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920302465 https://www.scopus.com/record/display.uri?eid=2-s2.0-85084420528{\&}origin=resultslist{\&}sort=plf-f{\&}src=s{\&}sid=a28715a63d62b405efbba5b4a9835ff2{\&}sot=autdocs{\&}sdt=autdocs{\&}sl=18{\&}s=AU-ID{\%}28565047949},
volume = {169},
year = {2020}
}

@inproceedings{Daylidyonok2018,
abstract = {This paper describes the application of hierarchical tempo- ral memory (HTM) to the task of anomaly detection in human motions. A number of model experiments with well-known motion dataset of Carnegie Mellon University have been carried out. An extended version of HTM is proposed, in which feedback on the movement of the sensor's focus on the video frame is added, as well as intermediate processing of the signal transmitted from the lower layers of the hierarchy to the upper ones. By using elements of reinforcement learning and feedback on focus movement, the HTM's temporal pooler includes information about the next position of focus, simulating the human saccadic movements. Processing the output of the temporal memory stabilizes the recognition process in large hierarchies.},
author = {Daylidyonok, Ilya and Frolenkova, Anastasiya and Panov, Aleksandr I.},
booktitle = {Biologically Inspired Cognitive Architectures 2018. BICA 2018. Advances in Intelligent Systems and Computing},
doi = {10.1007/978-3-319-99316-4_10},
editor = {Samsonovich, Alexei V.},
file = {:C$\backslash$:/Users/panov/OneDrive/Documents/Mendeley Desktop/2019/Daylidyonok, Frolenkova, Panov/2019 - Daylidyonok, Frolenkova, Panov.pdf:pdf},
isbn = {978-3-319-99316-4},
keywords = {16-37-60055,17-29-07051,anomaly detection,elibrary,frccsc,hierarchical learning,hierarchical temporal memory,hse,htm feedback,myconf,processing,q3{\_}scopus,scopus,video},
mendeley-groups = {my{\_}publications},
mendeley-tags = {16-37-60055,17-29-07051,elibrary,frccsc,hse,myconf,q3{\_}scopus,scopus},
pages = {69--81},
publisher = {Springer},
title = {{Extended Hierarchical Temporal Memory for Motion Anomaly Detection}},
url = {https://link.springer.com/chapter/10.1007/978-3-319-99316-4{\_}10 https://www.scopus.com/record/display.uri?origin=recordpage{\&}eid=2-s2.0-85053179132{\&}citeCnt=0{\&}noHighlight=false{\&}sort=plf-f{\&}src=s{\&}sid=ad6a3bc81b605cd06b67867e7622bb15{\&}sot=autdocs{\&}sdt=autdocs{\&}sl=},
volume = {848},
year = {2019}
}

@inproceedings{Skrynnik2016,
abstract = {Hierarchical temporal memory is an online machine learning model that simulates some of the structural and algorithmic properties of neocortex. The new implementation of hierarchical temporal memory is proposed in the paper. The main distinction of the implementation is chain extraction module that complements the spatial and temporal polling modules of HTM. The new module simplifies cross-level regions connection implementation (e.g. feedback). An experiment is also described to illus- trate how hierarchical temporal memory with explicit states extraction works.},
author = {Skrynnik, Aleksey and Petrov, Alexander and Panov, Aleksandr I.},
booktitle = {Biologically Inspired Cognitive Architectures (BICA) for Young Scientists. Advances in Intelligent Systems and Computing},
doi = {10.1007/978-3-319-32554-5_28},
editor = {Samsonovich, Alexei V. and Klimov, Valentin V. and Rybina, Galina V.},
file = {:C$\backslash$:/Users/panov/OneDrive/Documents/Mendeley Desktop/2016/Skrynnik, Petrov, Panov/2016 - Skrynnik, Petrov, Panov.pdf:pdf;:C$\backslash$:/Users/panov/OneDrive/Documents/Mendeley Desktop/2016/Skrynnik, Petrov, Panov/2016 - Skrynnik, Petrov, Panov.doc:doc},
keywords = {16-37-60055,elibrary,hse,myconf,scopus,wos,wos{\_}cpci},
mendeley-groups = {my{\_}publications},
mendeley-tags = {16-37-60055,elibrary,hse,myconf,scopus,wos,wos{\_}cpci},
pages = {219--225},
publisher = {Springer},
title = {{Hierarchical Temporal Memory Implementation with Explicit States Extraction}},
url = {http://link.springer.com/10.1007/978-3-319-32554-5{\_}28 https://www.scopus.com/record/display.uri?eid=2-s2.0-84964038709{\&}origin=resultslist},
volume = {449},
year = {2016}
}

@inproceedings{Gorodetskiy2020,
abstract = {This work is devoted to unresolved problems of Artificial General Intelligence is the inefficiency of transfer learning. One of the mechanisms that are used to solve this problem in the area of reinforce- ment learning is a model-based approach. In the paper we are expanding the schema networks method which allows to extract the logical rela- tionships between objects and actions from the environment data. We present algorithms for training a Delta Schema Network (DSN), predict- ing future states of the environment and planning actions that will lead to positive reward. DSN shows strong performance of transfer learning on the classic Atari game environment.},
author = {Gorodetskiy, Andrey and Shlychkova, Alexandra and Panov, Aleksandr I},
booktitle = {Artificial General Intelligence. AGI 2020. Lecture Notes in Computer Science},
doi = {10.1007/978-3-030-52152-3_18},
editor = {Goertzel, B. and Panov, A. and Potapov, A. and Yampolskiy, R.},
file = {:C$\backslash$:/Users/panov/OneDrive/Documents/Mendeley Desktop/2020/Gorodetskiy, Shlychkova, Panov/2020 - Gorodetskiy, Shlychkova, Panov(2).pdf:pdf},
isbn = {978-3-030-52152-3},
keywords = {17-29-07079,18-29-22027,delta schema network,frccsc,mipt,model-based,myconf,q2{\_}scopus{\_}prelim,reinforcement learning,schema network,scopus,transfer learning},
mendeley-groups = {my{\_}publications},
mendeley-tags = {17-29-07079,18-29-22027,frccsc,mipt,myconf,q2{\_}scopus{\_}prelim,scopus},
pages = {172--182},
publisher = {Springer},
title = {{Delta Schema Network in Model-based Reinforcement Learning}},
url = {https://link.springer.com/chapter/10.1007/978-3-030-52152-3{\_}18 https://www.scopus.com/record/display.uri?eid=2-s2.0-85088532072{\&}origin=resultslist{\&}sort=plf-f{\&}src=s{\&}sid=b407ed849d0c75e7a90799c322d3e284{\&}sot=autdocs{\&}sdt=autdocs{\&}sl=18{\&}s=AU-ID{\%}2856504794900{\%}29},
volume = {12177},
year = {2020}
}
